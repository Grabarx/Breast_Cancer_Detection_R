---
title: "Projekt na 'Metody statystyczne i analityczne Big Data' - Michał Grabicki"
author: "Michał Grabicki"
date: "7 01 2021"
output: html_document
---
## Cel:
Budowa modeli klasyfikacyji przy pomocy regresji logistycznej, metodzie kNN oraz random forest
w celu ustalenia, czy rak piersi jest łagodny, czy złośliwy. Sprawdzenie skutecznosci modeli.


## Ładowanie bibliotek.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tree)
library(randomForest)
library(plotly)
library(corrplot)
library(devtools)
library(gmodels)
library(caret)
library(class)

```

## Wczytywanie danych. 

```{r}

wdbc<- read_csv("wdbc.csv", skip = 1,
# Zmieniam nazwy kolumn na bardziej czytelne. 
                col_names= c("id","diagnosis","radius_mean","texture_mean","perimeter_mean",
                 "area_mean","smoothness_mean","compactness_mean","concavity_mean",
                 "concave_points_mean","symmetry_mean","fractal_dimension_mean",
                 "radius_se","texture_se","perimeter_se","area_se","smoothness_se",
                 "compactness_se","concavity_se","concave_points_se","symmetry_se",
                 "fractal_dimension_se","radius_worst","texture_worst","perimeter_worst",
                 "area_worst","smoothness_worst","compactness_worst","concavity_worst",
                 "concave_points_worst","symmetry_worst","fractal_dimension_worst"))

#Usuwam zbedna zmienna "id".
wdbc <- select(wdbc, -1)

#Sprawdzam ilosc kolumn, strukture danych oraz glowne statystyki zbioru.
ncol(wdbc)
str(wdbc)
summary(wdbc)

```
Zbior sklada sie z 30 zmiennych objasniajacych i 1 zmiennej objasnianej "diagnosis". Zbior jest czysty, to jest nie posiada brakow w danych.

##Kategoryzacja zmiennej zależnej.
```{r pressure, echo=FALSE}
#kategoryzacja zmiennej zależnej

wdbc$diagnosis <- factor(wdbc$diagnosis, levels = c("B", "M"),
                         labels = c("0", "1"))

wdbc$diagnosis <- as.numeric(as.character(wdbc$diagnosis))
#Ponownie sprawdzam podstawowe cechy zbioru.
str(wdbc)
table(wdbc$diagnosis)
prop.table(table(wdbc$diagnosis))
summary(wdbc)

```

#Macież korelacji.
```{r}
cor_matrix <- cor(wdbc[,1:ncol(wdbc)])
corrplot(cor_matrix,order = "hclust", tl.cex = 1, addrect = 8)
```
##Eliminacja zmiennych silnie skorelowanych na podstawie macieży korelacji. 
```{r}
wdbc2 <- wdbc %>% select(-findCorrelation(cor_matrix, cutoff = 0.9))
#Ponownie sprawdzam strukture danych
str(wdbc2)
ncol(wdbc2)
summary(wdbc2)

```

##Podzial zbioru na treningowy 80% i testowy 20% (w sposób losowy).
```{r}
# tworzyme zbiór treningowy i testowy ze zmiennych niezależnych

wdbc_random <- sort(sample(nrow(wdbc2)*0.8))
wdbc_train <- wdbc2[wdbc_random,]
wdbc_test <- wdbc2[-wdbc_random,]
# sprawdzam rozklad zmiennej diagnosis 
table(wdbc_train$diagnosis)
table(wdbc_test$diagnosis)

# #usuwam zmienna diagnosis ze zbioru treningowego i testowego - do knn
# wdbc_train_knn <- wdbc_train[-1]
# wdbc_test_knn <- wdbc_test[-1]

# tworzyme zbiór treningowy i testowy ze zmiennej zależnej - do knn
wdbc_train_labels <- wdbc2[wdbc_random, 1]
wdbc_test_labels <- wdbc2[-wdbc_random, 1]

prop.table(table(wdbc_train_labels))
prop.table(table(wdbc_test_labels))
```

##Regresja logistyczna.
```{r}
# Rozpoczynam trening modelu regresji logistycznej
set.seed(1234)
wdbc_reg_log<- glm(data = wdbc_train, formula = diagnosis ~ ., family = binomial(link = "logit"))
summary(wdbc_reg_log)

```
##Ocena modelu regresji logistycznej.
```{r}
##Przepuszczamy dane przez model.
res <-predict(wdbc_reg_log, wdbc_train, type = "respons")


#Confusion Matrix
confMatrix <- table(Actual_Value=wdbc_train$diagnosis,Predicted_value= res > 0.5)
confMatrix

#Badamy Accuracy
(confMatrix[[1,1]]+ confMatrix[[2,2]]) / sum(confMatrix)


# log_reg_probs <- predict(wdbc_reg_log, wdbc_train)
# log_reg_cm<- confusionMatrix(log_reg_probs, wdbc_test$diagnosis,positive = "M" )
# help("predict")
# 
# xtab <- table(wdbc_reg_log, wdbc_train)
# # load Caret package for computing Confusion matrix
# confusionMatrix(xtab)
# 
# 
# ## testing for random forets
# pred_rf <- predict(model_rf, test_data)
# cm_rf <- confusionMatrix(pred_rf, test_data$diagnosis, positive = "M")
# cm_rf
```

##Normalizacja danych. Zmienne sa w roznych skalach.
```{r}
#tworzyme funkcję normalizującą zmienne
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}
#Normalizuje zbior danych
wdbc_normalized <- as.data.frame(lapply(wdbc2[2:ncol(wdbc2)], normalize))

# Tworze nowe zbior treningowy i testowy 
wdbc_train_normalized <- wdbc2[wdbc_random,]
wdbc_test_normalized <- wdbc2[-wdbc_random,]

# tworzyme zbiór treningowy i testowy ze zmiennej zależnej - do knn
wdbc_train_labels <- wdbc2[wdbc_random, 1]
wdbc_test_labels <- wdbc2[-wdbc_random, 1]

prop.table(table(wdbc_train_labels))
prop.table(table(wdbc_test_labels))
```

##Regresja logistyczna na zbiorze znormalizowanym.
```{r}
# Rozpoczynam trening modelu regresji logistycznej na zbiorze znormalizowanym
set.seed(1234)
wdbc_reg_log_normalized<- glm(data = wdbc_train_normalized, formula = diagnosis ~ ., family = binomial(link = "logit"))
summary(wdbc_reg_log_normalized)

```

##Ocena modelu regresji logistycznej na zbiorze znormalizowanym.
```{r}
##Przepuszczamy dane przez model.
res_log_n <-predict(wdbc_reg_log_normalized, wdbc_train_normalized, type = "respons")

#Confusion Matrix
confMatrix_log_n <- table(Actual_Value=wdbc_train_normalized$diagnosis,Predicted_value= res > 0.5)
confMatrix_log_n

#Badamy Accuracy
(confMatrix_log_n[[1,1]]+ confMatrix_log_n[[2,2]]) / sum(confMatrix_log_n)

```
W przypadku regresji logistycznej normalizacja nie zmienia wyników modelu. 

##Regrecja logistyczna na zbiorze znormalizowanym po usunieciu nieistotnych zmiennych.
```{r}
# Rozpoczynam trening modelu regresji logistycznej na zbiorze znormalizowanym po usunieciu nieistotnych zmiennych.
set.seed(1234)
wdbc_reg_log_normalized2<- glm(data = wdbc_train_normalized, formula = diagnosis ~ area_mean + radius_se + texture_se  + smoothness_se + fractal_dimension_se + texture_worst + fractal_dimension_worst, family = binomial(link = "logit"))
summary(wdbc_reg_log_normalized2)

```

##Ocena modelu regresji logistycznej na zbiorze znormalizowanym po usunieciu nieistotnych zmiennych.
```{r}
##Przepuszczamy dane przez model.
res_log_n2 <-predict(wdbc_reg_log_normalized2, wdbc_train_normalized, type = "respons")

#Confusion Matrix
confMatrix_log_n <- table(Actual_Value=wdbc_train_normalized$diagnosis,Predicted_value= res > 0.5)
confMatrix_log_n

#Badamy Accuracy
(confMatrix_log_n[[1,1]]+ confMatrix_log_n[[2,2]]) / sum(confMatrix_log_n)

```
Również w przypadku regresji logistycznej usunieciu nieistotnych zmiennych nie zmienia wyników modelu, Accuracy pozostaje bez zmian.

#KNN - K najbliższych sasiadów.
```{r}
#ustalam wartosc k
k <- round(sqrt(nrow(wdbc_train_normalized)),0)
##21 - to sporo, jesli proces bedzie zbyt dlugi bedzie mozna sprobowac zmniejszyc wartosc k.
wbcd_test_pred <- knn(train = wdbc_train_normalized, test = wdbc_test_normalized,
                     cl = wdbc_train_labels, k = 21)

```





